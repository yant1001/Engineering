# 이론
## 전통적인 데이터 처리 방식
- 전통적인 데이터 처리 방식은 다음과 같이 시스템 A가 시스템 B에 데이터를 요청할 때 **동기적**으로 요청
- 동기 통신이란?
  - A가 요청하면 B가 처리 후 A에게 결과를 돌려줄 때까지 A가 기다린다.
- 비동기 통신이란?
  - A가 B에게 요청하면, B가 처리하고 있는 것과 별개로 A는 계속 할 일을 한다.
  - 비동기적으로 데이터를 받아올 때는 `RabbitMQ` 같은 Message Queue 또는 배치 처리 방식을 사용했었다
  - Message Queue를 구현해낸게 `RabbitMQ`
- 다만 여러가지 메시지가 추가되고 연결고리가 얽힐수록 복잡한 모양새를 띄게 된다
- 이렇게 되면 발생하는 문제는? 
  - 관리가 어렵다.
  - 시스템별 통신 프로토콜이 다를 경우 각각 구현이 필요하다.
  - 중간에 시스템이 망가지면 일일이 연결된 곳들을 다 점검해야 하므로, POF(Point Of Failure가 많아진다)
- 최근의 데이터 엔지니어링은?
  - 여러 소스에서 여러 형식의, 여러 프로토콜의 많은 양의 데이터를 수집할 수 있다.
  - Kafka는 이러한 시스템 복잡도를 줄여주는 대표적인 플랫폼이다.
- Kafka는?
  - 카프카는 링크드인에서 개발함
  - 카프카 개발팀이 나와서 또 회사를 차림 (confluent)
  - 실무에서 사용하는 카프카는 90% 이상이 conflunet
  - 실시간 데이터 수집, 처리에 많이 사용되지만, 대용량 네트워크 시스템에도 (거의 원톱으로) 사용된다.


## 카프카를 이용한 아키텍처
- 시스템 서로간 연결 의존성을 아예 제거
- 수집에 대한 파이프라인에서, 오로지 카프카를 통해야만 데이터 레이크에 적재된다.
- 카프카를 이용하면 시스템별 프로토콜이 다르더라도 그 내용은 카프카만 신경쓰면 되기 때문에 각 시스템의 통신 프로토콜을 통합하기 쉬워진다.
- 이 때문에 각 시스템에서 보낸 메시지를 보관하고 처리하는데 특화되어 있는 프레임워크


## 카프카 대표적인 구성 요소⭐
### Topic
- 카프카 안에서 전송되는 메시지가 저장되는 장소를 **논리적으로 표현하는 개념**
- 논리적인 저장소 개념으로, 실체가 존재하지 않는다.
- 시스템 상의 파일이나 디렉토리 형식으로 확인 불가능
### Producer
- 메시지를 만들어서 카프카의 토픽으로 보낸다.
- 메시지를 발생시켜서 프로듀서에게 발송하면 내가 지정한 곳으로 이동시켜준다.
  - 어플리케이션이라 직접 만들 수 있다.
### Consumer
- 프로듀서가 토픽에 메시지를 쌓게 되면, 그 메시지를 컨슈머가 가져간다(소비한다).
- 여러 개의 컨슈머 가능 (컨슈머 그룹으로 관리된다)
- 컨슈머 그룹은 최소한 1개 이상의 컨슈머를 갖는다.
- 하나의 컨슈머 그룹에 포함되어 있는 여러 컨슈머들이 협력해서, 토픽의 메시지를 분산 병렬 처리한다.


## 카프카 내부 구성요소와 아키텍처
### Broker
- 카프카의 서버는 곧 브로커이다.
- 프로듀서와 컨슈머가 브로커에 접속해서 원하는 토픽에 데이터를 Produce하거나 Consume한다.
### Partition
- 하나의 토픽은 파티션이라는 개념으로 나뉜다.
- 개념적인 내용인 토픽과 달리, 파티션은 실제 메시지가 저장되는 공간으로, 실체가 있다.
- 각 파티션에 메시지가 저장되며, 오프셋이라는 순번을 갖는다.
  - 순서가 절대 꼬이지 않게 설계되어 있다.
### Consumer Group
- 1개의 컨슈머 그룹은 최소한 1개 이상의 컨슈머를 갖는다.
- 컨슈머만 만들어도 컨슈머 그룹이 자동으로 만들어진다.
### 클러스터 구성
- 토픽은 추상적인 개념으로, 하나의 토픽이 여러 브로커에 생길 수 있다.
- 여러 서버에 동시에 걸쳐서 만들어질 수 있는 토픽 (추상화된 데이터 저장소 같은 느낌)
  - RDD와 비슷하다
### Zookeeper
- 주키퍼 자체가 카프카만을 위한 시스템은 아니다.
- 각종 분산 시스템에 대한 메타 데이터 정보의 저장을 담당
- 카프카에서의 주키퍼는, 클러스터 관리 & 토픽 관리 & 파티션 리더 관리
- 토픽이 어떤 브로커, 파티션에 저장되어야 최적화가 될지 계산하는게 주키퍼


## 토픽의 구성요소
- 카프카의 토픽은 데이터 스트림이 어디에 공급(Publish)될지 정하는데 사용
  - 스트림 == 데이터가 목적지에 도달할 수 있도록 흘러다닐수있는 통로(물길)
  - 전달한다 (x)  데이터를 흘려보낸다 (o)
- 파일 시스템의 폴더의 개념과 유사
- 프로듀서는 지정한 토픽에 메시지를 게시(post)하고, 컨슈머는 토픽으로부터 데이터를 받아온다.
  - 카프카에서 데이터를 저장(게시 post)할 때 바이트 형식으로 저장하며 바이트로 저장하기 때문에 아주 용량 낮음 효율적
- 이 때 카프카의 메시지는 디스크에 **정렬되어 저장**되며 새로운 메시지가 도착하면 지속적으로 로그에 기록
### 파티션
- 토픽은 파티션의 그룹으로 볼 수 있다. (토픽 > 파티션)
  - 즉 토픽은 파티션으로 이루어짐, 파티션에 오프셋을 부여하며 메시지가 저장된다.
- 프로듀서가 메시지를 보내면 토픽 안에 어딘가에 있는 파티션에 메시지가 기록
- 프로듀서가 공급한 데이터를 컨슈머가 가져가면서, 파티션에 기록된 데이터는 절대 변하면 안되기 때문에 불변성(Immutable)이라는 특징
### 메시지
- 메시지와 데이터는 유사 (연속적으로 들어오는 작은 데이터)
- 메시지가 쌓이면 데이터가 된다 (batch 형태)
  - 다만, 데이터는 이미 쌓여있는 것, 메시지는 지금 보내지고(전송되고) 있는것
  - 메시지는 이벤트라는 이름으로도 불린다. (비슷한 용도로 혼용됨)
- **(중요) 카프카의 메시지는 Byte배열 형식으로 되어있다**
- 메시지의 형식은 일반적으로 문자열, json, Avro를 사용
  - Avro는 타입이 존재하는 json
- 카프카 메시지의 크기에는 제한이 없으나, 실시간으로 데이터를 빠르게 공급하고 소모하기 위해 작게 유지하는 것을 권장
  - 보통 메시지 크기가 1MB를 넘어가지 않게 설정 (1MB면 거의 100만 자의 영어 표현 가능)
- 사용자가 지정한 시간만큼(Retention Period) 메시지 저장된다.
  - 기본적으로 일주일
  - Retention Periods가 지나면 메시지는 삭제되며, 컨슈머가 메시지를 받아가고 나서도 Retention Peroid가 끝나지 않았다면 데이터는 유지된다.


## 파티션과 메시지 저장 방식
- 카프카는 여러 개의 브로커(서버)를 가질 수 있다.
- 토픽은 하나여도 브로커 여러개에 나눠져서 저장될 수 있다.
  - 토픽 하나가 여러 개의 브로커에 나눠서 저장된다면, 해당 토픽을 위한 파티션 또한 여러 브로커에 걸쳐서 생성된다.
### 메시지 종류
- Key의 존재 유무에 따라 파티션에 저장되는 방식이 달라진다.
- Key가 존재하지 않는 메시지
  - round robin 방식으로 파티션 분배
  - 순환되어 처리하는 방식. key가 모자라면, 다시 1번 파티션으로 들어가는 방식.
  - 각 파티션마다 돌아가면서 저장되는 방식
  - (Key가 존재하지 않는 메시지 방법으로만 실습할 예정)
- Key가 존재하는 메시지
  - 같은 Key의 메시지는 같은 파티션에 보내진다.


## 복제 인수 (Replication Factor)
- 여러 브로커에 걸쳐 메시지를 복사해 저장한다.
  - 예를 들어, 복제 인수를 2로 설정한다면 모든 브로커에 걸쳐 파티션이 2개씩 존재하게 된다.
  - 복제된 파티션 중 대표를 하는 파티션 리더를 갖게
  - 파티션 리더를 통해서만 읽기와 쓰기 연산이 이루어짐으로써, 컨슈머가 복제된 동일한 메시지를 가져오는 현상을 방지할 수 있다.
- 메시지 복제는 클러스터의 장애 허용을 위한 필수 과정


## Consumer Group
- 카프카에서 컨슈머 생성 시 따로 컨슈머 그룹을 생성하지 않는다면 각각의 컨슈머는 고유한 컨슈머 그룹을 갖게 된다.
- 컨슈머 그룹은 모든 파티션으로부터 데이터를 받는다.
- 특정 컨슈머는 지정된 파티션으로부터 데이터를 받는다.
  - 컨슈머 그룹이 물리게 되면, 지정된 파티션으로부터만 데이터를 받을 수 있게 설정된다
  - (주키퍼가 계산한 결과를 토대로)
### Consumer Rebalancing
- 컨슈머와 파티션의 짝이 맞지 않는 경우에는, 임의의 컨슈머에게 잠시 남는 파티션의 데이터를 수신하도록 하고, 추후 새로운 컨슈머가 추가되면 담당케 한다. (리밸런싱 작업)



# 설치
1. 주키퍼 열기 (AWS 접속)
- `$KAFKA_HOME/bin/zookeeper-server-start.sh $KAFKA_HOME/config/zookeeper.properties`
2. 브로커 열기 (AWS 접속)
- ` $KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties`
- 정상 실행 확인 `netstat -an | grep 9092`
- 주키퍼에 정상 접속 확인 `netstat -an | grep 2181`
3. 카프드롭 열기 (Local 접속)
- `java --add-opens=java.base/sun.nio.ch=ALL-UNNAMED -jar kafdrop-3.29.0.jar --kafka.brokerConnect=<host_address>:9092`
- `http://localhost:9000/`으로 확인 가능
- 카프카를 콘솔창으로만 관리하면 불편하기 때문에 웹사이트로 구축해둔 프로그램
- 자바로 만들어짐


# 실행
- 분할 탭을 열어서 주키퍼, 브로커, 카프드롭 순차 연결
- (새 파워쉘) 분할 탭을 열어서 프로듀서와 컨슈머 연결 창
- 프로듀서 1개, 컨슈머 2개일 때
  - 컨슈머 생성 시 별도 지정을 하지 않으면 각자 컨슈머 그룹을 독립적으로 갖는다.
  - 2개의 컨슈머가 서로 다른 그룹이라면, 프로듀서에서 메시지를 보낼 경우 컨슈머 모두에게 전달된다.
  - 2개의 컨슈머를 같은 그룹으로 지정한다면, 프로듀서에서 메시지를 보낼 경우 컨슈머 한 쪽에만 전달된다.
- 프로듀서 2개일 때
  - 프로듀서 어느 쪽에서 보내든, 붙어있는 컨슈머 2개가 같은 컨슈머 그룹이라면 한쪽에서만 메시지 출력된다.
  - 프로듀서와 컨슈머는 연결관계가 없다.
  - 파티션하고만 연결관계가 있다. (메시지는 파티션에 round robin 방식으로 분배된다)
  - 만약 컨슈머 여럿이라면, 파티션과 컨슈머 개수에 집중해야 한다.
- 파티션 하나에 컨슈머 그룹이 하나씩 붙는다.
  - 파티션이 4개라면 컨슈머 그룹은 2개 혹은 4개 등의 배수로 설정되어야 (그나마) 밸런스있게 사용 가능
## 메시지 전달 과정
- Producer에서 Topic으로, Topic에서 Consumer로 Stream 통로가 뚫린다.
- Topic에서 Consumer로 연결되는 통로는 Message Queue
  - Queue에 쌓인 메시지를 Consumer가 가져간다는 개념
  - Queue 데이터가 들어올 때까지 Consumer는 무한 대기 (Block 된다고 표현)
## 실습
1. vs코드 - 형식이 없는 plain 텍스트 방식으로 topic 주고받기
2. vs코드 - json 형식으로 topic 주고받기
   - topic을 보낼 때는: dict ——dumps—→ 문자열 ——encode—→ 바이너리
   - topic을 받을 때는: dict ——loads—→ 문자열 ——decode—→ topic
3. vs코드 - 신용카드 이상탐지 app 생성
4. vs코드 - batch 데이터로 모델을 만들고, streaming으로 보내기
   - OCP 원칙(개방 폐쇄 원칙): 코드를 한번에 다 적지 말고, (레고 조립하듯) 기능들을 효율적으로 분류하여 프로그램을 만들어야 한다는 의미