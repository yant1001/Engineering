# Spark 설치

# Spark의 등장 배경
## 대량 데이터 처리를 위한 분산 데이터 아키텍처
- (기본적으로 하둡과 같이 작동된다.)
- MPP (Massively Parallel Processing)
  - 대용량 병렬 처리 개념의 등장
  - 매우 비쌈
- HDFS (Hadoop Distributed File System)
  - MPP가 사장되고 HDFS가 뜨기 시작했다.
  - 대용량 병렬 처리를 저렴한 비용으로 수행할 수 있게 해준다.
  - 맵리듀스와 더불어서 빅데이터의 시대를 열었다는 평가를 받는다.

### 1. MPP의 등장
- 컴퓨터마다 각각 다른 컴퓨터로 이루어지고, 데이터베이스 파티션으로 구분되어 서로 다른 DB를 갖는다.
- 중앙 서버가 명령을 내리면, 명령을 받은 컴퓨터들이, 각자 데이터를 분할하여 병렬로 처리한다.
  - 하나의 DB가 여러 디스크로 나뉘어, 데이터를 병렬로 처리한다.
- 문제점?
  - 각각의 컴퓨터가 연결되고 개개별 세팅 돼야 하므로 비용이 비싸다.
  - join을 수행해서 집계를 하면 서로 다른 컴퓨터에 있는 데이터가 필요할 수도 있다. 그럴 경우 네트워크 통신이 너무 많아지고 속도가 느려졌다.
    - 모든 연산 중 네트워크 연산이 가장 느리다.
  - 분리한 DB의 크기가 커지면, 다시 분할을 해야 하거나 Scale-Up을 해야하는 등 지속적으로 운영하기에 해결할 부분들이 존재했다.
    - 하드웨어 및 내부연결 레이어를 구축하기 위한 비용이 많이 들었다.
- 효과적인 데이터 처리를 위한 구글의 GFS 논문이 발표되면서, 해당 내용을 토대로 Yahoo의 Hadoop이 등장한다.

### 2. MPP에서 HDFS로
#### Yahoo의 분산 파일 처리 시스템
1. HDFS
   - 파일 시스템으로, 하나의 파일을 여러 컴퓨터에 분산 저장한다.
   - MPP의 interconnect 레이어를 대체할 수 있었다.
2. Map Reduce
   - Map(데이터 표현) Reduce(데이터 줄이기)
   - 연산 엔진으로, 데이터를 집계(분석)한다.
   - HDFS로 분산 저장된 파일을 맵리듀스를 이용해 빠르게 집계할 수 있다.
   - 집계는 곧 분석을 의미한다. 데이터분석은 집계로 한다!
3. Yarn
   - 리소스 관리, 즉 클러스터를 관리한다.

#### 맵리듀스를 대체하는 스파크
- 맵리듀스는 java를 이용해야만 하는 한계가 존재했고, 이를 대체해서 연산 엔진이 가능한 Spark가 대두되기 시작했다.
- 언어에 국한될 필요없이, 파이썬, SQL, Pandas도 사용할 수 있도록 Data Frame도 등장했다.
- 사실 HDFS가 유명해면서 이를 연구하려고 만들어진게 spark. 기업에서 만든게 아니라 대학원생이 테스트를 위해 만들었다. 사용하다 보니 스파크만의 리소스매니저가 필요하여 만들어졌으나(MESOS), 유지되지 않고 MESOS 대신 하둡의 Yarn을 사용하게 되었다.
- Spark는 다루다보면 분석가의 영역이라고 느낄 수도 있지만, 엔지니어링 지식을 가지고 스파크를 활용하는게 요즘 트렌드
- 기능
  - RDD, DataFrame, SQL 기반의 데이터 처리 추상화
  - DAG 기반의 실행 최적화
  - In-Memory 기반 수행
  - 맵리듀스 대비 빠른 수행 시간과 자원 최적화

# 메모리의 계층 구조 이해하기
- 속도: CPU > L1 캐시 > L2 캐시 > L3 캐시 > RAM > HDD/SSD 
- 용량: HDD/SSD > RAM > L3 캐시 > L2 캐시 > L1 캐시 > CPU
- CPU는 컴퓨터의 뇌, 캐시는 자주 쓰이는 자잘한 데이터들(이름, 전화번호 등)을 의미한다.
- 속도와 용량은 반비례하며, 속도 순위가 내려갈수록 차이가 매우 많이 난다. (용량도 마찬가지)
  - L1 CACHE: 0.5 나노초
  - L2 CACHE: 7 나노초
  - RAM: 100나노초
  - HDD/SSD: 8,000,000 나노초
- 연산이 시작되면 HDD/SSD로부터 CPU까지 데이터가 이동한다.
- 연산에 자주 사용되는 데이터는 위쪽에 저장된다.
  - CPU 방향, 즉 속도가 빠르고 용량이 낮다.
- 연산에 자주 사용되지 않는 데이터는 아래쪽에 저장된다.
  - HDD/SSD방향, 즉 속도가 느리고 용량이 크다.

# 인메모리 연산
- L1, L2 캐시는 빠르지만 용량이 매우 작고, HDD/SSD는 너무 속도가 느리기 때문에 대부분 적당히 빠르고 적당히 용량이 확보되는 RAM을 인메모리 연산에 많이 활용한다.
- 인메모리 연산이란?
  - HDD/SSD(보조기억장치)에 있는 데이터를 RAM으로 가지고 와서 CPU가 RAM에서만 작동할 수 있도록 하는 연산 방법이다.
  - 따라서 RAM의 용량을 최대한 확보하는 것이 좋다.
- 인메모리 연산의 한계
  - RAM은 일반적으로 8~32GB, 많으면 64GB이기 때문에 대용량 데이터 처리에 한계가 있다.
  - 그래서 디스크와 협업하여 대용량 데이터도 처리를 해보자는게, 스파크의 기본 아이디어이다.
- Spark의 인메모리 연산
  - 메인 연산은 RAM에서 수행하되, RAM이 부족한 경우에는 디스크(HDD/SSD)와 RAM을 스위칭하여 사용한다.
    - 디스크는 속도가 느리더라도 대용량의 데이터를 저장할 수 있기 때문에 가능한 방법이다.
    - 메모리를 계속 켜두어야 한다. (ElasticSearch의 Memory Swap과 유사)
  - 다만 스위칭이 반복되면 너무 느릴 수 있기 때문에, **대용량의 데이터를 분할해서 여러 노드의 메모리에서 동시에 처리**하는 분산 시스템(HDFS) 방법을 사용한다.
    1. Leader(마스터역)가 Follower(워커역)에게 명령을 내린다
    2. 분할된 데이터를 컴퓨터 자체의 메모리(RAM)에 올려서 연산한다.
       - 하둡이 데이터를 분할하여 작게 저장하면, 스파크가 축소된 데이터로 메모리 연산을 수행한다.
       - 하둡과 스파크가 함께 움직이기 때문에 버전업도 함께 이루어진다.
  - 여러 컴퓨터에서 분할된 데이터로 인메모리 고속 연산이 가능해진다.

# Spark Cluster
## 작업순서
- 순서
  1. 클라이언트가 마스터에게 제출을 한다.
  2. 마스터는 그 프로그램을 모든 워커들에게 전부 전달한다.(업로드)
     - 최대한 많은 작업이 워커 내부에서 일어나게 하는 게 좋다.
     - 어쩔 수 없는 경우에만 네트워크를 이용하여 다른 노드에 있는 내용을 구성해야 한다.
     - 워커 입장에서 데이터노드에 있는 데이터를 가져다 빠르게 사용할 수 있다는 것, 다시 말해 네트워크를 통해 노드를 넘나들며 데이터를 주고받는 것 대신 로컬에서 처리 가능한 내용을 빠르게 처리할 수 있다는 것은 훨씬 빠른 작업 수행이 가능해진다는 의미이다.
     - 최대한 네트워크 타는 걸 줄여서 효유적으로 코딩을 할 수 있어야 하며, 이 러한 환경에서 분석 결과를 내야 하는 게 분석가의 역할이다.
- 스파크는 RAM에 데이터를 올리고 내리는 과정을 굉장히 많이 반복하는 인메모리 연산을 수행하므로 SSD가 어울린다.
- 스파크를 사용하지 않고, 데이터 저장소로만 사용할 목적이라면, HDD가 어울리는 경우도 많이 존재한다.

## 스파크 클러스터 구성
- 코딩을 하는 건 클라이언트, 작업을 받아오는 건 마스터, 실행은 워커 노드가 수행한다.
- Cluster Manager(네임노드, 마스터)와 Worker Node(데이터노드, 워커)는 눈에 안보이는 내부적인 부분이나 구조를 반드시 알고 있어야 이해에 도움이 된다.
1. Driver Program
- Task 프로그램을 작성한다. (python, java, scala 등 사용)
- 개념적으로 보면, driver program이 job이고 그 코드 조각이 task이다.
- driver program 안의 spark context 상에서 작업하면 그 내용이 마스터에게 전달된다.
- spark context가 존재함으로써, 클라이언트가 코딩을 하면 코딩 내용이 마스터에게 전달되고 실제 실행을 위한 작업은 워커노드에게 뿌려지는게 가능해진다.
- 이 때문에 스파크는 spark context를 설치하는 것부터 시작된다.
그래서 스파크의 시작은 스파크콘텍스트를 설치하는것부터이다
2. Cluster Manager
- 클러스터 매니저 == 리소스 매니저
- 하둡의 Yarn이 해당된다.
- 스케줄링 담당한다.
- driver program으로부터 받은 task를 worker에게 분배한다
3. Worker Node
- 연산을 수행하는 파트
- 기본적으로 CPU 1개당 노드(서버) 1개를 배치하는 게 가장 좋다.
  - 예를 들어, 16 Core 컴퓨터에는 노드 16개가 가장 최적화된 상태이다. 하지만 그 이상 돌릴 수도 있긴 하다.
- CPU 내에는 1개의 프로세스를 처리할 수 있는 스레드가 있다. (이후 인프라 구성 관련하여 다시 등장)
- 워커 노드 안에는 driver program의 코드 조각이 task가 존재한다.

# Pandas VS Spark
- 일반 로컬 컴퓨터에서 스파크를 사용하면 pandas의 데이터 프레임보다 느리다.
  - 인메모리 연산으로 인해 디스크를 오가기 때문에 상대적으로 속도가 느리다.
  - 판다스는 연산 수행하겠다는 명령어를 입력하면 즉시실행(Eager evaluation)되지만, 스파크는 게으른 연산(Lazy evaluation)을 수행한다.
- 다만 스파크는 Pandas DataFrame보다 훨씬 많은 양의 데이터 처리가 가능하기 때문에 다양한 작업 수행이 가능하다.
  - 데이터프레임은 일정 파일 크기가 넘어가면 연산이 불가능하다.
  - 스파크는 용량이 아무리 커져도 연산 수행이 가능하다.
  - 그렇더라도 하둡 맵리듀스보다 스파크가 훨씬 빠르다.
- 스파크는 애당초 빠른 처리 속도가 목적이 아니라 대용량 데이터에 대한 수평적 확장성, 즉 조금이라도 더 빠르게 대용량 데이터를 처리하는게 목적인 데이터 처리 도구이다.
- 소규모 데이터로 비즈니스 로직이 목적이라면 pandas를 사용하는게 좋다.
- 하나의 프로젝트를 pandas와 spark를 이용한 분석 추천
  - spark로 프로젝트를 진행하고, 사이즈 축소 후 pandas도 적용해보는 것이 좋다. (여러가지 툴을 적용하여 하나의 분석 수행해보기)

# RDD (Resilient Distributed Dataset)
- 스파크의 핵심 데이터 모델이다.
- 스파크에서도 RDD 직접 사용해서 분석하는 걸 지양하고 있으며, 실제 데이터 분석 또한 RDD를 사용하진 않을 예정이나 그럼에도 불구하고 RDD가 스파크 구성의 최소 단위이기 때문에 알아두면 좋다.

## RDD 특징
1. 탄력적 분산 데이터 세트이다. (분산된 파일을 하나로 모은 데이터 세트)
2. 여러 분산된 노드에 **걸쳐서 저장**된다.
  - 데이터는 여러 클러스터에 흩어져 있지만 하나의 파일인 것처럼 사용이 가능하다. (데이터 추상화)
3. 변경이 불가능하다 (immutable)
   - 기존의 RDD가 변경되는게 아니라 변경된 새로운 RDD가 만들어지게 된다.
4. 여러개의 파티션으로 분리될 수 있다

## Resilient 탄력적의 의미
- RDD는 탄력적(Resilient)이다.
- RDD에 변환이 수행될 때마다 연산의 기록이 남게 된다. **(lazy evaluation)**
- 여러 곳에서 데이터가 연산되는 상황에서는 노드 중 하나가 망가지는 상황이 자주 발생한다. HA시스템(고가용성, 서버 이중화) 덕분에 작업을 완료지을 순 있지만 기타 문제로 인해 연산이 불가능한 상황이 발생 가능하다.
- 이때 스파크에서는 데이터의 불변성을 통해, 문제가 발생됐을 때 데이터셋을 구현하여 복원이 가능하다. **(immutable)**
  - RDD는 변환을 거치면 기존의 RDD가 변경되는 것이 아니라 새로운 변경 RDD가 생성된다.
- 예를 들어, [Node1]>>변환1>>[Node2]>>변환2>>[Node3]가 진행될 때 변환2 과정에서 장애가 발생하면 Node3에서 Node2로 복원하여 새로운 RDD를 생성한다. **(resilient)** 
  - 위와 같은 RDD의 변환 과정을 비순환 그래프(Acyclic Graph)로 표현할 수 있고, 이러한 일자 방향의 비순환 그래프를 **DAG**라고 한다.
  - DAG를 그려가면서 연산을 수행하고, 끊어지면 다시 다른 노드가 탄력적으로 작업을 이어받아 수행 가능하다.
### 데이터 추상화
- 데이터 자체는 여러 클러스터에 흩어져 저장된 상태이지만, 하나의 파일인 것처럼 사용이 가능하다. (ex. `sc.textfile(filename)`)


## Lazy Evaluation 이해하기
- RDD의 가장 중요한 특성으로, 바로 연산되지 않고 **연산의 기록만** 계속 쌓이는 것을 의미한다.
- 즉 게으른 연산(lazy evaluation)이란 task를 정의할 때 즉시 연산을 하지 않고, 결과가 필요할 때 연산을 수행한다.
- 기다리면서 연산 과정의 최적화가 가능하다.
- 연산의 기록만 남는 단계는 **Transformation(변환)**, 실제 연산이 수행되는 단계는 **Action(액션)**으로 구분한다. (드물게 예외 존재하긴 함)
- 이 구조로 인해 RDD에는 항상 작업의 시작과 끝이 존재하고, 연산 중 문제가 생기면 이전 RDD로 돌아갈 수 있게 된다.
- 연산의 기록이 남아있기 때문에 다른 노드가 연산을 이어받아서 수행할 수 있다. (연산의 Resilient)
- 스파크는 애당초 대용량 데이터 처리를 목적으로 만들어졌기 때문에, 판다스처럼 즉시실행이 이루어지면 메모리 사용량이 급격하게 커지게 된다. 그렇기 때문에 메모리 용량을 줄이기 위해 **게으른 연산** 전략이 적용된다.
  - 심지어 로딩 중에도 실제 RDD를 만들지 않아서 메모리가 사용되지 않는다.
  - action을 취할 때만 메모리가 사용된다.
  - action 수행을 하면 그 시점부터 모든 작업 내용을 처리하기 때문에 시간이 오래 소요된다.


## Transformations와 Actions
- 각각의 데이터를 내가 원하는 형식으로 흩뿌려주는 것을 Mapping이라고 한다.
- 주피터 노트북 상에서 결과값에 RDD라고 출력되면 Transformation, 리턴값이 출력되면 Action이 수행된 것이다.
1. Transformation 변형 함수
   1. `.filter()`
   2. `.map()`
2. Action 액션 함수
   1. `.collect()`


# 실습
1. 주피터 노트북 접속
2. 데이터 업로드
3. 변형(transformation) 함수와 실행(action) 함수 적용
4. 스파크 작업을 웹UI로 출력 (4040포트)