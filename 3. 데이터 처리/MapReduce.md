# Hadoop MapReduce
- 맵리듀스란 2004년 구글에서 발표한 데이터 처리 알고리즘이다.
- Map: 내가 원하는 방식으로 데이터를 늘어놓는것
  - 컬렉션에 있는 모든 원소들에 대한 변환 함수
- Reduce: 늘어놓은 데이터를 종류별로 모아서 합치는 것
  - 각 원소에 집계 함수를 적용하여 크기를 줄이는 함수


## 용어
- mapreduce job
  - 클라이언트가 수행하는 작업의 단위
- map task, reduce task
  - 맵리듀스 프로그램이 실행된 후 각각 map task와 reduce task로 나뉜다.
  - 각 task들은 yarn에 의해 스케쥴링 및 실행된다.
- inputsplit
  - 입력의 논리적인 단위
  - map task는 하나의 split을 처리한다.
  - mapper에 입력으로 들어오는 데이터를 분할하는 방식을 제공한다.


## InputSplit과 Block
- HDFS: 하나의 파일을 여러 개의 블록으로 만들어서 데이터가 저장된다.
- 하지만 Mapper에서 데이터를 불러올 때는 block 단위가 아닌 inputsplit 단위로 데이터를 불러와서 처리한다.
- 데이터를 읽기 위한 데이터 레코드들이 블록과 딱 맞아 떨어지지 않기 때문이다.
  - 하나의 데이터 레코드라도 여러 개의 블록으로 나누어진 경우가 있다.
  - 예를 들어 textinputformat의 논리적인 레코드(한개의 엔티티==한개의 행)가 128mb를 넘어간다면, 하나의 데이터를 의미함에도 불구하고 분리되어 다른 노드에 들어갈 수 있다.
- 이 때 Inputsplit 단위를 사용하여 데이터를 읽으면 논리적인 레코드가 블록의 경계를 넘어가도 문제가 되지는 않는다.
- 블록으로 나누면 128mb까지만 가능하지만, 논리적인 레코드를 기준으로 나누면 하나의 레코드로 처리할 수 있도록 추상화시킨 것이 inputsplit이다
  - inputsplit은 실제로 해당 파일을 읽을 때 블록의 경계를 넘어가더라도 블록의 경계를 넘어갔다는 정보 또한 있기 때문에 모두 포함된 정보를 갖는다.
  - 결국 블록 크기와 맞지 않더라도 맵리듀스는 데이터를 레코드 단위로 올바르게 처리할 수 있게 된다.


## 맵리듀스 처리 과정
1. 맵리듀스 작업이 시작되면 파일로부터 입력을 받는다.
2. 입력 파일은 split 돼서 map에 전달된다.
3. map의 처리 결과가 shuffle 과정을 통해 reduce 과정으로 전달된다.
4. reduce 과정이 끝나면 output이 출력된다.

### 맵리듀스의 대표적인 예시 WordCount
- 
- 원본 데이터가 들어오면 행 단위로 데이터가 split된다.
  - split된 3개가 각각 다른 컴퓨터들이다.
- 나눠진 split은 map에 입력되어 데이터가 흐트러뜨려진다.
- map에서 단어별로 입력 데이터를 분류하는 작업이 수행된다. (key:value 형태)
- combine 과정으로 전달된다.
  - map에서 combine 과정이 있는 이유는, 데이터를 합쳐내기 전에(shuffle) 관련성이 있는 데이터를 컴퓨터 내에서 집계하기 위함이다.
    - reduce 함수와 combine은 같은 과정을 거치게 된다.
    - (어차피 네트워크를 타야한다면 양이라도 줄이자!)
- map만 된 상태에서 dog을 이동시키기 위해 1번 컴퓨터에서 3번 컴퓨터로 이동하게 되면 2건이 이동해야되는데, combine된 상태라면 1건만 이동해도 된다
- 즉 이동 데이터 양을 줄여준다
- shuffle은 종류별로 데이터를 모아서 섞어주는 과정 (셔플일 통해 네트워크 통신이 이루어짐)
- reduce는 shuffle된 결과를 합쳐 하나로 나타내는 과정

wordcount 과정을 거쳐 데이터를 집계한다