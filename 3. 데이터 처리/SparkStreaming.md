# Spark Streaming
- SQL 위에서 만들어진 분산 스트림 처리 프로세싱이기 때문에 DataFrame이 거의 강제된다.
  - 즉 DF 처리할 때 사용 가능하다.
  - RDD도 가능하다.
- 데이터 스트림을 처리할 때 사용 가능하다.
- Kafka, HDFS 등 이종 간 연결이 가능하다.
  - 이 중 카프카로 보낸 로그 정보를 스파크로 받아 집계하는 실습 진행 예정
  - 카프카로 데이터를 받아냈으면, 스파크 스트리밍으로 어떻게 할 수 있을지?
- 부분적인 결함이 발생해도 미리 만들어둔 체크포인트로 돌아갈 수 있기에 대응이 수월하다.
- **(데이터가 들어오는) 시간대별 집계가 가능하다.**
## Stream Data
- 데이터 스트림은 무한한 데이터 테이블로, (미래에) 무한한 데이터가 들어올 것을 가정한다.
  - 이미 쌓인 데이터가 batch data
  - 실시간 데이터가 stream data
- 현시점에 들어오는 데이터가 스파크 스트리밍을 통해 배치 데이터가 된다는 개념
- 이 때 데이터를 받아내는 방식이 Micro Batching
- Micro Batching으로 쪼개진 배치는 데이터 프레임, 배치 데이터와 비슷하게 보이는 개념이기 때문에 추후 데이터 프레임처럼 다룰 수 있게 된다.
- 즉 **Micro Batching을 통해 데이터를 받아서 데이터 프레임처럼 다룰 수 있다**는게 스파크 스트리밍의 기조
- 진행 단계
  - 무한한 데이터가 흘러 들어온다. (데이터 스트림)
  - spark streaming이 데이터를 받아 잘개 쪼개서 (마이크로 배칭) spark engine으로 보낸다.
- 쪼개진 배치는 데이터 프레임과 비슷하게 처리 가능하다.
- spark engine을 거쳐서 나온 데이터는 일반적인 데이터 프레임과 같이 저장된다.
## DStream (Discretized Stream)
- RDD와 아주 유사하며 사용방법이 거의 비슷
  - RDD 기반으로 만들어진게 스파크 데이터 프레임
- spark streaming에서 사용하는 데이터 프레임은 DStream을 기반으로 만들어진다.
  - spark stream의 기본적인 추상화
  - 내부적으론 RDD의 연속이고, RDD의 속성을 이어받는다.
  - DStream이 spark streaming의 결과물, 즉 spark streaming에서 나와 spark engine으로 가기 전 단계의 데이터 모습이다. (마이크로 배칭으로 잘게 쪼개진 데이터)
- 불변성과 분산 저장 속성을 이어받아, DStream도 transformations를 거쳐 새로운 DStream을 만들 수 있게 된다.
- 각 batch 별 쪼개진 상태에서 그대로 transformations가 일어나, 시간순으로 정리된 형식의 새로운 DStream이 만들어진다.
데이터 변환을 다 하고 마지막에 액션을 때린다
## Streaming Query: Source
- 데이터를 어디에서 읽어올지 명시한다.
  - 이것만 정하면 끝난다.
- 처리한 데이터 저장 및 기타 스트림에 대한 여러 처리를 수행한다.
  - 여러 데이터 소스를 사용해 join()이나 union()으로 합쳐서 쓸 수 있다.


## 스파크 프로세싱
- 스파크는 기본적으로 **배치 프로세싱**을 지원하는 도구
  - 큰 데이터셋에 대해 한 번 연산을 처리
- spark streaming을 통한 **스트림 프로세싱**도 함께 지원
  - 끝없이 들어오는 데이터의 흐름을 연속적, 준 실시간으로 처리


## 스트림 처리 기법들
1. 레코드 단위 처리 모델
   - 플링크가 대표주자 (다른 툴보단 어렵)
   - 각 노드에서 지속적으로 한 개의 레코드를 받으며, 해당 레코드를 처리하여 생성된 다른 레코드는 또 다음 노드로 보낸다. (실시간)
   - 응답 시간이 아주 짧지만, 높은 처리량을 달성하기 어렵고 특정 노드에 장애가 발생하면 복구하기 어렵다.
   - 실시간 채팅이나 문자중계가 아니면 굳이 레코드 단위 모델 사용하지 않는다.
2. 마이크로 배치 스트림 처리 모델
   - spark streaming에서 기본적으로 사용하는 방식 (대표 주자)
   - 마이크로 배치 스트림 처리 모델만 써도 훌륭하게 처리 가능
   - 스트림 처리를 아주 작은 배치 처리 방식으로 수행한다. 
     - 예를 들어, 유튜브 좋아요 수 집계는, 실시간 처리되어야 하긴 하지만 한사람 한사람이 누를때마다 바로 반응할 필요는 없다. 때문에 일정량 데이터를 조금씩 모아서 실시간으로 반영하는 마이크로 배치 스트림 모델을 일반적으로 많이 사용한다.
   - 높은 처리량이 장점이다.
   - 단점은, 대부분의 데이터 파이프라인에서 시간의 오차가 생길 수 있다는 것 (데이터가 부정확할 수 있다)
     - 예를 들어, 유튜브 댓글에서 좋아요가 적지만 상위군에 올라와 있는 경우가 있다.

## 스파크 스트리밍 종류
- 스파크 프레임워크에서는 배치와 스트리밍을 다루는 코드가 매우 비슷하디.
1. DStream
   - RDD처럼 사용 가능 (RDD API 기반)
   - (RDD와 같이) 개발자들이 작성한 코드와 동일한 순서로 연산 수행 (자동 최적화X)
2. Spark Structured Streaming
   - DataFrame처럼 사용 가능 (가장 베스트 방법)
   - DStream의 단점을 극복하고, streaming processing 코드 작성이 batch processing 코드 작성만큼 쉬워야 한다는 게 기본 원칙
   - 데이터의 스트림을 무한하게 연속적으로 추가하는 데이터의 테이블 개념으로 간주하는 기법이다. 스트리밍 데이터를 테이블이라는 틀로 흘러들어오는 정형화된 데이터로 간주하기 때문에 배치 기본 문법을 모두 사용 가능하다.
   - 결과 테이블이 갱신될 때마다 **세 가지** 기능 제공
     1. `append` 모드
        - 결과 테이블에 새롭게 추가된 행만 기록
     2. `update` 모드
        - 결과 테이블에 갱신된 행만 기록
     3. `complete` 모드
        - 갱신된 전체 테이블을 기록 (모든 데이터)


## Window Function
- 데이터의 특정한 범위를 지정하고, 해당 범위 내에서 집계 함수 등을 적용하는 함수
- 기본적으로 시간의 범위를 기준으로 하는 **time-based-window**만을 사용
  - time-based-window: 내가 설정한 시간 기준에 따라 시간대를 만드는 것
  - window의 시간 범위는 micro batch와 무관하다.
  - 일반적인 partition by와 같은 window function은 사용 못한다.


### 대표적인 윈도우 설정
- window duration
  - window의 크기
  - 30분, 5분, 1시간 등의 시간 크기를 의미
- window sliding interval
  - window 사이의 간격


## 윈도우 종류
1. Sliding Window
   1. 고정된 크기의 윈도우를 가진다.
   2. **윈도우 사이 겹치는 구간** 존재
   3. 시간을 좀 더 유동적으로 흐르게 할 수 있다.
   4. 윈도우 1과 2 사이에 interval이 있다. (겹치는 구간으로 인한 간격 존재)
      1. 시간대 크기, 윈도우의 크기(window duration)보다 interval이 작다.
      2. 즉 윈도우 2는 1, 3과 겹치게 된다. (실시간 검색어 개발할 때 많이 사용)
2. Tumbling Window
   1. 고정된 크기의 윈도우를 가진다. (슬라이딩 윈도우와 유사)
   2. 다만 윈도우간 겹치는 구간이 없다.
   3. 윈도우 크기는 똑같지만 포함된 이벤트가 모두 다르다.
   4. 시간대별 카운트를 사용할 때 자주 쓴다.
      1. 사람들이 많이 들은 노래, 14-15시 사이 인기 검색어 등과 같은 구현 시 사용
3. Session Window (실습 pass)
   1. 윈도우 크기가 가변적이다.
   2. 처음 윈도우가 생성된 후 이벤트가 설정한 gap duration 이내에 들어오면, 그 시간 안에 window가 점점 확장된다.
      1. 이벤트가 duration 안에 안 들어오면 해당 윈도우는 그냥 끝나버린다.
      2. 새로운 이벤트가 들어오면 새로운 윈도우가 생성된다.
   3. 이벤트가 몰리면 윈도우가 확 커지면서 모든 이벤트를 다 잡아서 집계 가능하다.
      1. 콘서트 예매나 사이트 오픈런 같이 특정 시간에 몰리는 경우 세션 윈도우가 어울린다.
   4. 다만 이벤트에 의존적이다.


## 시간 기준별 윈도우 처리 방식
1. Event time windows
   - 이벤트 타임을 기준으로 입력 데이터 처리
   - 클라이언트의 액션이 일어난 (이벤트가 실제 생성된) 시간
   - 로그에 이벤트 타임에 대한 정보가 반드시 있어야 한다.
     - 반드시 시간 정보는 필요하기 때문에, 타임 스탬프를 많이 사용한다.
   - 이벤트타임을 훨씬 많이 쓴다 (사용자에게 무슨 일이 일어났는지 아는게 최우선이기 때문)
   - 사용자 중심으로 데이터를 바라볼 때 유리
2. Processing time windows
   - 프로세싱 타임을 기준으로 입력 데이터 처리
   - 스파크 세션, 즉 서버가 메시지를 받은 시간
   - 시간에 대한 정보가 없어도 상관 없다.
     - 시간 재는 건 스파크 서버가 그냥 데이터가 들어온 시간을 기록해주면 되기 때문
     - `current_timestamp()`를 통해 생성된다.
   - 성능 모니터링이나, 어느 순간에 서버 부하가 걸리는지 찾기 위해서는 프로세싱 타임을 많이 사용하기도 한다
   - 서버 중심으로 데이터를 바라볼 때 유리


## event+window 및 output mode**
- 스파크 스트리밍 종류 중 Structured Streaming에서 결과 테이블 모드로 `append`, `update`, `complete`를 지원한다.
- 모드에 따른 변화는 아래와 같다. (슬라이딩 윈도우로 예시)

1. output mode = `complete`
   1. (예를 들어) 9시 5분에 발생된 데이터가 엄청나게 늦게 output에 들어왔다면, 오류가 아니라 이벤트 발생 후 스파크 어플리케이션 도달까지의 시간 지연된 경우로 판단 가능하다.
      1. 시간 범위에 포함되는 윈도우 1과 2에 모두 포함되어야 한다.
2. output mode = `update`
   1. 갱신된, 즉 업데이트가 된 윈도우에 대해서만 처리된다.
      1. 예를 들어 해당 윈도우의 수치가 갱신된 경우에만 결과로 가져온다.
   2. 그룹바이가 윈도우로 된다
3. output mode = `append`
   1. 과거 데이터는 신경 쓰지 않는다.
   2. 새롭게 갱신된 이벤트만 보기 때문에 집계 자체가 배치별로 따로 처리된다.


## Watermarking
- 처리된 데이터에서 쿼리에 의해 검색된 최대 이벤트 타임보다 뒤쳐지는 이벤트 타임의 동적인 임곗값
  - 이 시간 동안 기다려줄건데, 이 시간 지나면 넌 버려지는 데이터야~ 하고 이야기하는 기준점이 되는게 워터마크
- 워터마크보다 작은 이벤트 타임을 갖는 이벤트는 쿼리 집계 대상에서 제외된다.
- 이를 사용해서 스파크 쿼리의 결과를 계산하고 유지해야 하는 상태 정보의 양을 줄일 수 있다.
- 보통 워터마크는 이벤트 타임과 같다.
- Max 데이터가 클수록 방금 들어온 최신데이터



# 실습
## Spark Streaming 실습
- stream으로 받으려면 데이터를 바이너리화(2진법) 해서 받아야 한다.
- 바이너리화 된 데이터가 다시 decode(사람이 읽을 수 있는 형태) 되어 문자열로 DStream, DataFrame에 들어온다.
- 이 때 무조건 `value`라는 이름의 DataFrame 컬럼이 만들어지고, 그 안에 데이터가 마이크로 배칭된다.
  - DataFrame에는 컬럼이나 스키마 정보 등이 필요한데, stream으로 받는 데이터는 그런 구조화가 하나도 되어있지 않다.
  - 때문에 value라는 컬럼이 생성되어 모든 정보가 흘러들어가게 된다.
  - 해당 컬럼에서부터 전처리(transform) 되며 집계가 이루어진다.
- socket 통신 ~ nc 사용
  - socket으로부터 나오는 데이터를 마이크로 배치화 되어 있는 데이터 프레임으로 받을텐데, 이때 value라는 컬럼만 거른다.
- 스트리밍 결과물 저장은 워커에서 수행된다.
  - 워커에서 프린트해서 보여주고, 저장도 해주고 등등 워커에서 수행된다.
  - 파일 저장은 task로 치지 않는다.
## Window Function 실습
- 
## Watermarking 실습
- 
## Kafka와 Spark Streaming 연동 실습
- 