# 병렬처리와 분산처리
- 병렬분산처리라고 합쳐서 많이 부른다.
- Spark는 RDD에서 작업을 수행하고, 함수가 task의 역할을 한다.
  - `datas.map(lambda row: row.split(",")[2])`
  - `datas`는 RDD이고 `lambda ~ [2]`는 task에 해당한다.
  - 함수로 작업을 등록(아직 실행X)하는것
- 클라이언트가 함수를 마스터에게 전달
- 함수를 마스터가 파악해서 스케쥴링 후 적절한 워커한테 TASK로 등록
- 워커는 TASK에 맞춰 실행 
- RDD에서 TASK를 돌린다라고 생각하면 된다.

## Data-Parallel 작동 방식
- 데이터를 한 노드에서 처리하기 버거운 경우
1. 데이터를 여러개로 쪼갠다
2. 여러 데이터가 들어있는 여러 쓰레드가 각자 task를 수행한다
    1. cpu 1개당 작업 1개만 수행한다
        1. cpu에는 thred라는게 있다.
        2. cpu는 thred가 다루는 노예의 손 개수
        3. 한 노드가 고구마밭이라면, 데이터가 4개로 쪼개졌을 때 고구마밭이 4개가 된다 
        4. cpu가 손 한개로 캐는 것보다 나눠진 밭을 4개의 스레드로 동시에 캐는게 더 빠르다
    2. task는 작업 수행 도구 (즉  rdd는 고구마밭, task는 작업 수행도구)

- cpu 하나당 노드 하나를 배치하는게 가장 이상적이다. 
- 때문에 기본적으로는 cpu가 node하나를 맡아야 하지만, 너무 크니까 데이터를 쪼개서 스레드를 이용해서 작업을 나눠서 처리하고 각각의 결과물을 합친다 == 병렬처리 (한대의 컴퓨터 하나의 cpu에서 벌어지는 일)

## Distributed Data-Parallel 작동 방식
- 분산 병렬처리
- 네트워크를 통한 분산 환경에서의 병렬처리
1. 데이터를 여러개로 쪼개서 여러 노드로 보낸다 (분산시스템)
2. 여러 노드에서 각자 독립적으로 task를 수행한다
    1. 이 때 spark context에 작성된 프로그램이 각 워커에 전달된다
3. 각 노드에서 작업된 task 결과물을 합쳐준다
- 상황에 따라서 노드 하나가 크다면 다시 잘라서 스레드로 관리한다
- 노드간 통신에 신경써야할 게 늘어난다
- 하지만 이런 모든 밸런싱도 스파크가 다 알아서 해준다

## 데이터 병렬 모델 추상화
- 데이터 추상화 == 대충 아는 것
- 스파크는 분산된 환경에서의 데이터 병렬 모델을 구현해 추상화시켜준다.
- 이걸 구현해놓은 것이 바로 RDD(Resilient Distributed Datasets)
- RDD라는 개념 자체가 분산된 환경에서도 병렬처리를 할 수 있도록 알아서 처리한다(데이터가 추상화되었기 때문에 가능)
- RDD를 기반으로 만든 sql이나 데이터프레임도 동일하다
- 노드간 통신 등 통신 속도를 신경써야 하긴 하다! 하지만 스파크가 알아서 해주긴함


# 분산처리와 레이턴시
## 분산처리 문제
- 부분 실패 문제
  - 하나가 망가졌다고 전체가 망가지면 안된다
- 속도
  - ⭐**많은 네트워크 통신을 필요로 하는 작업은 속도가 저하된다**
  - 느려지는 요인: 횟수와 네트워크 통신 데이터 크기
- 어떤 작업을 어떻게 코드로 나타내는가에 따라 달라지는 속도
  1. 횟수는 어쩔 수 없다
  2. 데이터의 크기는 프로그래밍적으로 제어할 수 있다
     1. 데이터의 크기 == 네트워크를 통과하는 건수
     2. HDFS에서의 combine과정: 데이터의 속성은 변하지 않으면서 데이터의 절대적인 건수가 줄어들도록 한다
     3. 불러올 데이터를 `filter()` 함수로 줄여준 다음,  데이터를 불러와서 `reduceByKey()` 합쳐준다
        1. 마치 집계과정. 퍼포먼스가 제일 뛰어나다
        2. 초보자의 입장에선 뭘쓰든 상관없다고 생각할 수 있지만 속도면에서 차이가 난다
        3. 무조건 필터링하고 집계를 하는게 속도가 빠르다. 마치 where절에서 데이터를 거르고 group by하는 순서로 sql 쿼리가 진행되는 것과 같다


# Key-Value RDD
- 데이터 집계의 핵심이 되는 RDD 구조
- key value 상을 갖기 때문에 pairs RDD라고도 한다
- 딕셔너리같지만 딕셔너리보단 튜플의 모양이다
  - (key, value) 쌍을 갖는다.
  - `pairs = rdd.map(lambda x: (x, 1))`
  - 리스트도 value가 될 수 있다.
  - `pairs = rdd.map(lambda x: (x, [1, 1]))`
  - map 변환 전에는 짜장면, 짬뽕으로만 적힌 rdd 형태이지만, map이라는 mapping 변환 작업을 거치면 (짜장면, 1)과 같은 key value rdd가 된다(리스트도 가능~짜장면, [1, 1])
- key를 기준으로 고차원적인 연산이 가능하다
- single value rdd는 단순 연산 수행
  - 텍스트 등장 단어수, 날짜수 세기
  - 그룹바이가 불가능하다
  - 그룹핑이 안되기 때문에 조건에 맞게 기준을 세울 수 없다
- key value rdd는 key에 따른 다양한 고차원적 집계 연산이 가능
  - 영화 장르별 평균 점수 계산, 날짜별 주문 개수, 날짜별 승객 수 등
  - 그룹바이가 가능하다
  - 조건에 맞는 기준을 세울 수 있다
## Key-Value RDD의 Reduction 연산
- reduction은 데이터를 줄여준다.
- reduction은 key 값을 기준으로 데이터를 묶어서 처리한다.
- 


# 주피터 실습

# RDD Transformations & Actions (ppt p.143~)

## spark operation

transformations + actions

- transformations 함수
- actions 함수

(내용 추가 필요)

## Narrow Transformation

일대일 변환을 의미한다

다른 열이나 파티션의 데이터를 사용하지 않아도 된다

## wide transformation

wide는 다른 파티션의 데이터가 네트워크를 타고 이동을 할 수 있다. (수행시간이 많이 소요된다)

다른 파티션으로 데이터가 이동, 네트워크를 타고 이동 (파티션과 파티션, 노드와 노드) 하는 것 == shuffling

shuffling을 줄이는 방식으로 코딩을 해야한다

대부분이 데이터집계 함수, 즉 데이터의 개수가 줄어든다

느리다고 해서 안좋은게 아니고, 집계를 하기 위해서는 필연적으로 써야하는 transformation이지만 shuffling 즉 파티션의 변화가 최대한 일어나지 않도록 신경써서 사용해야 한다.

파티션을 이동하는 상황 = shuffling 상황이 재수없으면 로컬 안이 아닌 서로 다른 노드로 이동하게 될수도 있다

집계를 하게 되면 필연적으로 파티션 이동이 필요하다, 

# 주피터 실습

액션을 하고 나면 파이썬 리스트가 되기 때문에 더이상 RDD 함수를 사용할 수 없다

따라서 액션을 하고 난 후 다시 액션을 할 수 없다

# cache & persist

## cache (ppt p.174~)

(여기는 가볍게 지나가기)

스파크의 마스터-워크 구조

데이터는 여러곳에 분산되어있다

같은 연산이어도 여러 노드에 걸쳐 실행 가능

분산된 위치 즉 데이터노드에는 워커가 존재하며 마스터 명령을 수행

스파크 클러스터 구조

우리가 작성하는 드라이버 프로그램 (주피터노트북 스파크)

드라이버 프로그램은 모든 프로세스를 조작하며 메인프로세스를 수행, 등등 

스파크 워커 노드에는 executor가 항상 존재한다. executor가 task를 실행하고 데이터 저장 및 결과를 드라이버 프로그램에 전송한다

캐시에 넣어서 빠르게 전송 가능토록 한다

스파크 프로그램 실행 과정

마스터-워커 구조에서 크게 벗어나진 않는다

실제 스파크 코드에서 나타나는 부분

워커노드까지도 코드에 표시된다

## reduction

(이제부터 어렵고 중요)

**Transformations**

데이터의 변형을 일으키는 작업들 (map, flatmap, filter 등)

**Action**

액션의 대부분은 reduction이다

액션을 통해 실제 물리적인 reduction 작업이 일어난다

그래서 액션할 때 시간이 더 걸리는 것이다

데이터 분석은 대부분 reduction 작업을 요구하는 것

reduction이란? 근접하는 요소 즉 연관성 있는 것을 모아서 하나의 결과로 만드는 것

**병렬 처리가 가능한 reduction**

병렬 처리 가능 여부에 따라 결과물이 달라진다

각각의 task가 각각의 역할을 수행하고 결과를 합쳐서 새로운 task를 수행한다

새롭게 만들어진 task는 각각의 역할 수행 후 다시 결과를 합쳐서 또 새로운 task 수행

각 단계별 task들은 서로간 간섭이 일어나지 않는다

다만 이런 병렬 처리 상황에서는 파티션이 중요하다

task가 파티션마다 돌아간다

**병렬 처리가 불가능한 reduction**

task가 각각 진행되었지만, 파티션이 다른 파티션의 결과값에 의존하기 때문에 병렬로 실행할 수 없다 즉 직렬이다

task의 종류가 다른 것이지, 직렬이고 병렬이라고 뭐가 좋고 나쁘고 하진 않다

다만 둘다 reduction 즉 데이터가 줄어든다

이왕이면 병렬처리가 빠르긴 하다

이렇게 직렬의 경우 분산 병렬 처리로 할 필요없고 컴퓨터 한대로 하는게 더 빠를 수 있다

**대표적인 reduction actions**

reduce fold groupBy aggregate ⇒ transformation과 관계없이, 명령어 입력하자마자 바로 action된다 (그냥 바로 실행)

# 주피터 실습 4

key value rdd operation & joins

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/b64306f9-0c27-4c8b-a37d-7b73bbed811d/ea64362a-7e6c-4b2a-861a-f43b34aae6c5/Untitled.png)

ㄴ 마치 직렬 처리와 같은 모양

(지금 hdfs 로 파일을 분산 처리해서 저장한 다음에, 분산 저장된 데이터들을 스파크로 처리하는 과정인거ㅓ죠 ?? 파티션이 잘 이해가 안가는데, worker node 각각을 파티션이라고 생각해도 되나요?  worker node 랑 파티션이랑 task 랑 개념이 잡힐듯 안잡힐듯 하네요..)

파티션 == 데이터를 구분하기 위한 단위

aws 인스턴스에 스파크를 설치해서, 로컬에서 스파크를 사용하고 있는 상황

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/b64306f9-0c27-4c8b-a37d-7b73bbed811d/13aa4c51-f646-49c8-8737-e0995d6c61bf/Untitled.png)

현재 상황 그림

glom() 함수를 쓰면 파티션의 정보를 알 수 있게 된다 

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/b64306f9-0c27-4c8b-a37d-7b73bbed811d/8efb0e40-d903-498b-b08d-2ead54800e84/Untitled.png)

데이터노드에 있는 데이터를 하나의 RDD로 모아 놓은것

RDD에 있는 파티션에서는 물리적으로 서로 다른 데이터노드에 있는 데이터들을 마치 하나의 파티션처럼 개념적으로 사용할 수도 있다.

파티션은 데이터의 개념적인 분할방법이다

RDD는 추상화된 정보이기 때문에 물리적 상황과 상관없이 파티션을 꾸릴 수 있다

다만 RDD 상태에서 reduce를 하게 되면 데이터의 교환이 잦을 수 있다 즉 셔플링이 많이 일어난다

물리적으로는 떨어져있지만 개념적으로는 붙어있다

task는 파티션에 하나씩 분배가 되는

그래서 과거에는 이러한 파티션들을 다 고려한 코딩을 했어야 했지만  지금은 스파크 최적화로 그러지 않아도됨

데이터노드는 워커노드는 같은 개념이다

데이터노드가 워커노드와 다르게 존재해도 상관없다 다만 그렇게 되면 네트워크를 사용하게 된다..! 그래서 그렇게 안하기 위해 데이터노드 안에 워커노드를 띄우는것이다 (한지붕 두가족)

(인프라 엔지니어를 안하려고 하다면 몰라도 되는 지식이지만 사람일 모르는거니까~?)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/b64306f9-0c27-4c8b-a37d-7b73bbed811d/866c5fa2-2235-4e6a-86c0-c46e185a622f/Untitled.png)

rdd = sc.parallelize([1, 2, 3, 4], 2)
rdd.glom().collect()

파티션 내부 reduce task

seqOp = lambda x, y: (x[0]+y, x[1]+1)

파티션 연산 결과에 대한 reduce task

combOp = lambda x, y: (x[0]+y[0], x[1]+y[1])

rdd.aggregate((0, 0), seqOp, combOp)

# key-value RDD Operations & Joins

# shuffling & partitioning

## shuffling

한 노드에서 다른 노드로 옮길 때 네트워크 연산이 발생하는 것

노드마다 데이터들이 섞여있는 상태에서, 종류별로 묶으려고 한다면 정리가 필요 == 이때 종류별로 데이터가 모아지는, 섞어지는 과정을 shuffling이라고 한다

네트워크를 태우는 데이터의 개수를 줄이는게 중요하다

rdd를 여러 개 사용하는 경우에 셔플이 일어난다

특정데이터가 다양한 노드에 걸쳐 존재하는 경우에 셔플이 일어난다

groupbykey 후 reduce한다면? groupbykey에 의해 먼저 셔플이 일어난다

groupbykey때문에 병목이 일어나서 느려진다 (이러한 상황이 안좋은 예시)

좋은예시는?  reduce 하기 전 각각의 파티션에서 먼저 reduce과정을 한번 거치게 하는 것(데이터를 줄여놓고 섞는다)

(캐싱은 아직 안배워서 여기선 설명x)

결국, 셔플을 최소화하려면 리듀싱하고 섞어야 한다는 이야기

파티션의 목적: 비슷한 것끼리 놔둬야 검색이 쉬워지니까! (정렬과는 다르다)

파티션의 특징: ~ 하나의 노드는 여러 개의 파티션을 가질 수 있다~

파티션의 크기와 배치는 자유롭게 설정 가능하고 성능에 큰 영향을 미친다

파티션이 잘 되어야 rdd가 잘됨. 비슷한것끼리 예쁘게 모으는 알고리즘 == hash partitioning, range partitioning

hash partitioning이 기본이다

데이터를 여러 파티션에 균일하게 분배하는 방식이다 이걸 만들어주는게 해쉬 function

hash function ⇒ 어떤 정수 % 파티션 개수

데이터의 성질에 맞게 파티션 개수를 결정하는 것도 능력이다 (hash partitioning의 잘못된 사용 참고)

이런 잘못된연산을 skey라고 하고 이럴때는 병합을 해야하며 그에 따른 자원 낭비가 생길수도 있다

range partitioning은 범위 파티셔닝

순서가 있는 정렬된 파티셔닝

메모리와 디스크에 파티션 정의하기는 pass