# 분산 시스템의 이해
## 3-Tier Architecture
- Remote Call이 가능해지고 데이터의 전문 처리 시스템(DataBase)가 가능해졌다.
- 이로 인해 3-Tier Architecture(Client-Server-Database)가 온라인(웹) 서비스 구현의 하나의 패턴이 되었다.

## 기본 방식의 한계
- 2008년 음향회사였던 애플에서 아이폰을 출시하면서 스마트폰 시대가 시작되었다.
- 이때부터 인터넷을 본격적으로 사용하게 되었고, 데이터가 폭발적으로 증가하였다.
- 컴퓨터로는 쏟아지는 데이터량을 감당할 수 없어서, HDD, RAM 등의 사양을 높이는 방식(Scale-Up)을 시도하였으나, 방대한 트래픽과 데이터를 감당하지 못했다.

## 분산 시스템이 필요한 이유
- 기업 입장에서는 지속적인 Scale-Up 방식은 예산이 커질 뿐 효율적이지 못했다.
- 하드웨어의 덩치를 키우다 못해, 저렴한 컴퓨터를 여러 개 쓰자는 아이디어로 분산시스템이 등장한다.
- 따라서 서비스의 원활한 공급을 위해, 하드웨어가 아닌 소프트웨어에서 해결 방안을 찾게 된다. (GFS=>하둡)
- 분산시스템(Distribute File System : DFS)은 기본적으로 Scale-Out 방식이기 때문에 훨씬 경제적인 해결 방안이 되었다.
- Scale-Out은 물리적으로 떨어져있는 컴퓨터에 랜선을 꼽아 한대처럼 연결시키는 방식이며, 이를 성공시킨 회사가 하둡이다.
- 아직까지도 독보적인 영향력을 가지고 있어, 분산시스템은 곧 하둡이며, 빅데이터를 다룬다는 것은 곧 하둡을 다룬다는 의미와 동일하다.

## 분산시스템의 특징
- Concurrency (동시성)
  - 동시에 여러 작업 수행
- No Global Clock (비동기성)
  - A가 실행되고 있더라도 B와 C가 원하는 때에 병렬적으로 실행 가능 (== 비동기화)
  - 하나가 끝나야지만 다음이 시작될 수 있는 동기화의 경우 한 곳에서 문제가 생기면 실행이 멈추는(Lock) 문제가 있다. 다만 비동기에서도 같은 문제가 발생할 수는 있다.
- Independent Failure (실패로부터 독립)
  - A, B, C가 동작할 때 B에 문제가 생기더라도 A, C가 잘 동작해야 한다는 개념이다.
  - 즉 시스템 한 부분의 실패가 전체 시스템에 영향(장애)을 주면 안된다.

## 분산시스템의 고려 요소
- Heterogeneity (이식성)
  - 분산시스템은 여러 대의 컴퓨터를 사용한다는 의미이기 때문에, 서로 다른 시스템 사이에서 정보와 자원을 공유하며 동작할 수 있어야 한다.
  - 리눅스에서 분산시스템을 수행하고 있으나, 그 외 서로 다른 시스템에서도 분산시스템을 지원하는 경우가 있기 때문이다.
  - 즉 어떠한 환경에도 종속되지 않는 언어가 필요하다.
  - 대표적으로 객체지향 프로그래밍 언어인 java가 해당되며, java는 jvm만 OS에 맞게 설치되면 어디서든 동일한 코드를 실행시킬 수 있어 이식성이 좋은 언어이다. (+ 함수지향 Python 등)
  - C, C++ 등 Native Library에 대한 Dependency가 큰 언어로는 분산시스템을 개발하기 힘들다.
- Openess (개방성)
  - 서로 다른 요소 사이의 연결과 확장이 가능해야 한다.
- Security (보안성)
  - 권한제어, 접근제어 등이 가능해야 한다.
- Scalability (확장성)
  - 시스템 자원이나 사용자 수에 따라 확장 가능해야 한다.
  - 빅데이터 시스템에서는 주로 수평적 확장(Scale-Out)을 사용한다.
- Failure Handling (실패 제어)
  - 장애 및 실패에 대해 자동화된 방식으로 대응할 수 있어야 한다.
- Concurrency (동시성)
  - 여러 클라이언트가 하나의 공유 자원에 접근하는 등의 동시성에 대한 문제를 해결할 수 있어야 한다.
  - 예를 들어 클라이언트가 2명 이상일 때, 하나의 파일을 여러 컴퓨터에 나눠 담는 경우라도 함께 작업할 수 있어야 한다.
- Transparency (투명성)
  - 내부에 있는 정보를 보이지 않게 해야 한다.
  - 동일한 요청 한번에 모든 시스템을 전부 사용할 수 있어야 한다. (접근 투명성)
  - 컴퓨터들에 대한 정보 없이 리소스에 접근할 수 있어야 한다. (위치 투명성)
  - 원본과 복제본이 항상 똑같아야 한다. (복제 투명성)
  - 컴퓨터 중 하나에 문제가 생겨도 나머지 시스템은 영향을 받지 않고 작업을 마칠 수 있어야 한다. (실패 투명성) (복제 투명성 덕분에 가능)


# 빅데이터 엔지니어링
## 빅데이터와 빅데이터 플랫폼의 필요성
- 빅데이터는 물리적으로 Petabyte 이상의 굉장히 큰 데이터를 의미하며, 이러한 데이터로 효율적인 의사 결정과 기회 창출을 도모해야 한다.
- 오랜 시간 누적된 데이터는 기존의 방식대로는 분석과 예측이 불편하기 때문에 이를 위해 사용자들이 데이터를 처리하고 분석을 쉽게 할 수 있는 빅데이터 플랫폼을 구축해야 한다.
- 일반적으로 빅데이터 플랫폼을 구축하기 위한 요구 사항은 다음과 같다.
  - 데이터 수집, 처리 및 저장
  - 데이터 발견, 검색, 보안 제공
  - 데이터 분석 및 ML 지원
- 요구 사항을 충족한 이후에는 자동화를 통해 하나의 플랫폼을 만들어야 한다.
- 데이터 엔지니어는 이러한 플랫폼을 구축하여, 데이터로 하는 모든 업무를 서포팅하는 역할을 수행한다.
- 즉 엔지니어링에서 가장 중요한 부분은 설계이다. 
## Hadoop Eco System
- 하둡은 현 시점에서 가장 유명하고 탄탄한 빅데이터 플랫폼으로, 크게 원천 데이터, 수집 레이어, 처리 레이어, 저장 레이어, 분석&예측 레이어, 출력 레이어로 구성된다.
- `ELT`: 처리를 하지 않고 저장하는 것 (요즘 트렌드)
- `ETL`: 처리를 하고 저장하는 것

### 빅데이터 파이프라인
1. Data Source (원천 데이터)
   - 데이터 소스 선택
   - 데이터베이스, 파일 시스템, 네트워크 기반 데이터 소스 등 어디서 수집해야 하는지, 어떻게 수집해야 하는지, 어떤 데이터를 수집해야 하는지 결정해야 한다.
2. Data Ingestion & Processing (수집&처리 레이어)
   - 데이터 수집에는 실시간 데이터 수집과 배치 데이터 수집이 있다.
     - 실시간 데이터 수집과 처리
       - `realtime data` == 현재와 미래의 데이터, 즉 들어오고 있고 앞으로 들어올 데이터들
       - 대규모의 데이터 스트림에서 데이터를 실시간으로 수집하고 처리
       - Kafka, Flume, Nifi 등의 분산 메시징 시스템이나 Spark Streaming, Flink, Storm 등의 스트리밍 프레임워크가 사용된다.
     - 배치 데이터 수집과 처리
       - `batch data` == 이미 쌓여져 있는 과거의 데이터 (DataBase, File 등)
       - 큰 양의 데이터를 한 번에 수집하고 처리
       - Sqoop, Flume 등으로 배치 데이터 수집하며, 처리 속도는 느리지만 대규모 데이터 처리에 최적화되어 있다.
       - Hadoop MapReduce, Hive, Spark의 batch processing 등으로 배치 데이터 처리하며, 판다스도 동일한 역할을 수행한다.
3. 빅데이터 적재 (저장 레이어)
   - 데이터를 저장할 저장소를 선택하고, 데이터를 적재한다.
   - 데이터를 모델링, 인덱싱, 필터링, 병합하는 등의 작업을 수행한다.
   - 적재를 위한 저장소로 Hadoop HDFS, NoSQL의 DB인 MongoDB, Cassandra, HBase 등이 사용된다.
   - 데이터 레이크 => 데이터 웨어하우스 => 데이터 마트 순으로 구축된다.
   - 데이터 웨어하우스를 만들 때는 스파크나 하이브, 데이터 마트를 만들 때는 스파크를 주로 사용하며, 스파크 하나만으로도 웬만한 툴을 대체할 수 있다. (ML 구현, 실시간 분석도 가능)
   - 최근에는 다른 플랫폼과의 연결다리 혹은 환경을 구축하는 플랫폼 역할로만 하둡을 사용한다.
   - 하둡을 기반으로 한 분산시스템 핸들링은 필수적이다.
   - 데이터 레이크
     - 대규모 데이터를 실시간으로 수집, 저장, 처리한다.
     - `ELT`, `ETL` 등의 가공되지 않은 데이터를 데이터 레이크에 쌓아놓는다.
   -  데이터 웨어하우스
      -  대규모의 데이터를 저장하고 필요한 데이터를 위한 쿼리 실행을 위해 설계된 데이터베이스이다.
      -  데이터 레이크에 쌓여있는 데이터를 분류하고 전처리해야 하는데 이것을 컨테이너라고 하며, 곧 데이터 웨어하우스를 의미한다.
   -  데이터 마트
      -  데이터 웨어하우스에 분류된 데이터를 완벽한 상품으로 만드는 단계를 상품화 단계라고 한다.
      -  상품화된 데이터가 쌓여있는 형태를 데이터 마트라고 한다.
      -  데이터 마트로 저장된 데이터를 분석하게 된다.
4. 데이터 분석&예측 레이어
   - 데이터 마트까지 데이터 적재가 완료되면 분석&예측 레이어에서 데이터를 분석하고 예측 모델을 구축한다.
   - 데이터 시각화, 통계 분석, ML, DL 등의 기술을 활용한다.
5. 데이터 출력 레이어
   - 예측 모델을 바탕으로 데이터 시각화와 보고서 작성 등이 수행된다.
   - 분석에 대한 결과물은 태블로, 파워 BI, 아마존 퀵사이트 등으로 나타내며, 시각화 및 보고서 자료를 의사 결정에 활용하게 된다.
  

# Hadoop

