# GFS (Google File System)
- 하둡 분산 파일 시스템의 모태가 되는 구조다.
- 2003년 구글에서 발표한 논문에 해당 구조가 설명되어 있다.
- 크롤링 기업이었던 구글에서 쌓여가는 웹 자료들에 대한 관리 방안으로 나왔다.
- 가장 큰 주안점은 Master/Worker 구조로, GFS 클라이언트가 GFS 마스터에게 요청을 보낼 때 file name과 chunk index를 보내게 된다.
- GFS는 어느 GFS chunkserver에서 가져와야 할 지 지정해줘야 한다는 단점이 있었고, 이 것을 보완한게 바로 HDFS이다.

# Hadoop HDFS (Hadoop Distributed File System)
- 하둡의 분산 파일 시스템으로, 네트워크로 연결된 여러 머신의 스토리지를 관리한다.
- HDFS는 여러 컴퓨터의 파일 시스템을 네트워크로 엮어서 관리하기 때문에 보다 복잡한 형태를 띤다.
- 하나의 머신에서 장애가 발생하더라도 데이터가 유실되지 않도록 견고한 파일 시스템을 유지하는 것이 궁극적인 목적이다.
> 스토리지란?
> 
> 파일을 저장할 수 있는 기계를 의미한다. RDBMS는 관리만 할 뿐, 물리적으로는 데이터가 파일화되어 있기 때문에 이러한 디스크들을 통합하여 스토리지라고 일컫는다.

## HDFS Block
- HDFS에서 파일을 저장하는 단위이다.
- 하나의 거대한 파일을 여러 개의 블록으로 나눠서 저장하며, (하둡2부터는) 블록당 128MB를 갖는다.
- 하둡은 다른 분산 시스템보다 훨씬 큰 블록 사이즈를 갖는데, 그 이유는 디스크 탐색 비용(Seek Time)을 최소화하기 위함이다.
  - 블록 사이즈가 작아지면 블록을 찾는 시간(Seek Time)이 굉장히 많이 소요되기 때문에 블록 사이즈를 키워 시간을 단축시킨다.
- 블록 단위로 파일을 쪼개서 처리함으로써, 파일 하나의 크기가 실제 하나의 물리적인 디스크 크기보다 큰 경우에도 저장 가능해진다. (1TB를 초과하는 파일을 여러 클러스터에 블록으로 쪼개서 저장하기 때문에 1TB 용량의 하드 디스크를 여러 개 사용하여 더 큰 파일들을 저장할 수 있다.)
- 즉 하나로 안되니, 쪼개서 저장하자는 것이 분산 파일 시스템의 중심 아이디어이다.


## 특징
  - 범용 하드웨어를 사용하여 분산 파일 시스템을 구성하기 때문에, 저렴한 범용 컴퓨터로도 구현이 가능하다.
  - 블록 단위로 저장한다.
  - Master/Worker 구조를 갖는다.
  - 데이터를 복제하여, 한 대의 컴퓨터가 멈추더라도 다른 컴퓨터가 작업을 대신할 수 있다.
    - 장애가 일어났지만, 장애가 일어나지 않은 것처럼 작업을 이어나갈 수 있다. (장애 혀용 시스템 제공) (내고장성) (HA 시스템)
  - 하드웨어를 추가하면 용량이 증가하는 확장성을 제공한다.

## 구조
하둡의 Master/Worker 구조는 NameNode/DataNode 구조로도 설명이 가능하다.
1. NameNode
   - 메타데이터와 데이터노드를 관리하는 역할을 수행한다.
   - 메타데이터 관리
     - 어떤 데이터노드에 어떤 블록이 있는지에 대한 정보를 가지고 있다.
     - 메타데이터는 크게 FsImage와 EditLog로 구분할 수 있다.
     - FsImage(파일 시스템 이미지): 블록의 네임스페이스(원본 파일을 재구성할 수 있는 이름들의 집합 혹은 공간)HDFS에 저장된 데이터의 모든 정보 (즉 파일에 대한 상태 기록하는 메타데이터)
     - EditLog: 데이터노드에서 발생한 데이터 변환 내역, HDFS의 생성, 삭제, 수정, 트랜잭션(데이터의 처리 단위) 등에 관한 정보 (즉 하나의 파일에 대한 변경 내역 기록하는)
  - 데이터노드 관리
     - 클라이언트가 네임노드에게 요청을 하면, 네임노드는 데이터노드별로 작업을 분배한다.
     - 데이터노드가 처리 완료한 작업은 네임노드에게 블록 리포트로 전송되어 보고된다.
     - 데이터노드는 일정 주기마다 네임노드에게 자신의 작업 현황(상태)를 알리는 HeartBeat Packer을 보낸다.
2. Secondary NameNode
   - 네임노드에 대한 FsImage와 EditLog를 주기적으로 병합하는 과정을 수행한다. (네임노드의 스탠바이 역할이 아님)
   - FsImage는 생성되면 절대 변경되지 않기 때문에 HDFS가 작동하면서 변경된 내용은 모두 EditLog에 반영된다. EditLog는 크기 제한이 없어서 계속 쌓이기 때문에 네임노드 반영시간이 늘어나기 때문에 세컨더리 네임노드에서 FsImage와 EditLog를 병합(merge)해서 최신화된 FsImage 정보를 만든다.
   - 즉 Secondary NameNode에서 (Primary) NameNode의 FsImage 최신화를 책임진다. (로그 백업 및 시스템 상태 정보 최신화)
   - 가끔 의도치 않게 네임노드가 꺼져서 복구가 되지 않을 때, 병합하여 전달되었던 체크포인트를 삭제하면 다시 작동되는 경우도 있다.
   - 이를 통해 EditLog가 커지는 것을 방지하고 네임노드의 재구동 시간을 단축한다. (세컨더리 네임노드의 백업 정보로 복구도 가능)
3. DataNode
   - 데이터노드의 실제 블록 파일이 쪼개져서 저장된다.
   - 현재 자기 자신의 상태를 HeartBeat Packet을 이용해 주기적으로 전달하고, 만약 네임노드가 데이터노드에게서 Heartbeat Packet을 받지 못한다면 데이터노드가 작동하지 않는 것으로 간주하고 해당 노드에 데이터를 저장하지 않는다.
   - 저장하고 있는 블록의 변경 사항을 체크하고, 블록 레포트를 작성하여 네임노드에게 전달한다. 네임노드는 데이터노드에게서 전달받은 블록 레포트를 통해 메타데이터를 갱신한다.


## HDFS 저장 방식
- 파일을 나누면 블록이 되고, 블록 하나의 크기는 최대 128MB이다. (실무에서는 128MB 이상도 존재한다.)
- 나누어진 블록은 HDFS 내의 여러개의 데이터노드에 걸쳐 저장되며, 데이터노드에 있는 블록의 개수를 복제 인수(Replication Factor)라고 한다.
- 예를 들어, 전체 크기 374MB의 파일을 128/128/118MB(a/b/c)로 총 3개의 블록을 만든다. 데이터노드 또한 3개(A/B/C)를 만들고 복제 인수를 2로 설정한다면 (A: a, b), (B: a, c), (C: b, c)와 같은 형태가 된다. 복제 인수에 의해 데이터가 복제되었기 대문에 데이터노드 하나에 장애가 발생하더라도 블록 3개(a, b, c)를 모두 사용할 수 있다.

## HDFS 읽기 연산
- 데이터노드 3개에 블록 3개가 복제 인수 2인 상황을 가정한다.
- 클라이언트는 네임노드에 원하는 파일을 요청 => 네임노드의 메타데이터에서 어떤 데이터노드에 어떤 파일의 블록이 있는지도 관리 => 네임노드가 요청 파일에 대한 블록이 있는 데이터노드 위치를 클라이언트에게 전달 => 클라이언트는 네임노드가 전달한 정보를 토대로  데이터를 읽어온다.

## HDFS 쓰기 연산
- 클라이언트가 네임노드에게 파일 쓰기(저장 등) 요청을 보낸다.
- 네임노드는 클라이언트가 쓸 파일의 크기를 바탕으로 사용 가능한 블록이 있는 데이터노드 위치 목록을 클라이언트에게 전달한다.
- 클라이언트는 네임노드가 전달한 목록을 토대로 각 데이터노드에 저장을 한다.

## HDFS 추가 특징
- 블록 캐싱
  - 캐싱이란 자주 사용되는 정보를 빠르게 꺼낼 수 있도록 저장하는 것을 의미한다.
  - 하드디스크에 있는 데이터 중 자주 읽혀지는 블록을 메모리(RAM)에 캐싱하여 빠르게 사용할 수 있도록 한다. (인메모리 연산) (하둡은 느리더라도 데이터를 최대한 많이 저장하는게 목적이라 하드디스크를 많이 사용한다.)
  - 파일 단위로도 캐싱이 가능하다.
- HDFS Federation
  - 파일이 아닌 디렉토리 정보만 관리하는 것을 의미한다.
  - 네임노드는 파일 정보를 메타데이터로 관리하고, 메타데이터는 메모리를 통해서 관리한다. 하지만 HDFS에 파일이 많아지면 메타데이터를 위한 메모리 사용량이 증가하기 때문에 메타데이터를 위한 메모리 사용량이 증가하고 후에는 메모리 부족 등의 문제가 생길 수 있다.
  - 이를 극복하기 위해 (하둡2부터) 네임스페이스 단위로 각 디렉토리마다 네임노드를 실행해서 관리하기 시작한다. (네임스페이스 단위 == 디렉토리 단위) (블록에 있는 디렉토리 이름 하나만 기억하는 것)
- 고가용성
  - 네임노드가 망가지면 모든 작업이 중단될 수 있기 때문에 이를 막기 위해 Active NameNode와 Standby NameNode를 지원한다.
  - 평소에는 Active NameNode가 동작하다 문제가 발생하면 Standby NameNode가 동일한 메타데이터를 유지하고 있다가 Active NameNode가 되면서 지속적으로 동작한다.

## HDFS 명령어
- 기본 리눅스 명령어와 동일하다.
- HDFS와 관련된 명령어는 무조건 `hdfs dfs`로 시작한다.
- 기본 명령어
  - `-mkdir <파일경로>`: 디렉토리 생성
  - `-put <로컬파일경로> <hdfs경로>`(`-copyFromLocal`): HDFS 파일 업로드
  - `-ls <파일경로>`: HDFS 디렉토리 탐색
  - `-get <hdfs경로> <로컬파일경로>`(`-copyToLocal`): HDFS 파일 다운로드
  - `-mv <복사원본hdfs경로> <복사목적지hdfs경로>`: 파일 위치 옮기기 또는 파일명 변경
  - `wget`: 다운받아서 HDFS에 올리는 명령어
  - `head`: 앞 10줄 출력
- 실습 과정
  - `$HADOOP_HOME/sbin/start-dfs.sh`: HDFS 실행
  - `$HADOOP_HOME/sbin/start-yarn.sh`: YARN 실행
  - `hdfs dfs -mkdir /user/ubuntu/test`: ubuntu 계정으로 접근해서 디렉토리(폴더) 생성
    - `/user/ubuntu`가 HDFS의 홈 역할 (바탕화면, 루트)
  - `hdfs dfs -ls .`: 확인
  - `hdfs dfs -put /home/ubuntu/datasource/employees/employees /user/ubuntu/test/employees`: 앞서 `wget` 명령어로 다운받은 파일을 HDFS에 업로드
    - `/home/ubuntu/datasource/employees/employees`: 로컬경로
    - `/user/ubuntu/test/employees`: HDFS 경로
  - `hdfs dfs -ls /user/ubuntu/test`: 확인
  - `hdfs dfs -cat /user/ubuntu/test/employees`  파일 확인
  - `hdfs dfs -rm /user/ubuntu/test/employees`  파일 삭제
  - `hdfs dfs -ls /user/ubuntu/test` 잘 삭제되었는지 확인