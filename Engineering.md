# 데이터 엔지니어링의 목적
- 대용량 데이터 기반 의사결정을 만들기 위한 **인프라를 구성**
- 직접적인 의사결정을 하는 자리는 아니다.
- 결정을 도와주고 지원할 수 있는 인프라를 만드는 게 목적이다.
- HW, SW 모든 인프라에 대한 이해와 구성 능력이 필요하다.
  - 소프트웨어의 경우 설치 및 데이터레이크 → 데이터웨어하우스 → 데이터마트 까지 구성하는 능력 필요
- 엔지니어가 만들어둔 인프라 위에서 데이터를 활용할 수 있어야 하기 때문에,**분석가를 희망하더라도** 인프라에 대한 이해가 필요하고, 이 또한 경쟁력이 될 수 있다. (워낙 기본 소양이 돼가고 있기 때문)

# 데이터 엔지니어링의 전망
- 데이터를 이용해서 인사이트를 추출하는 업무의 대부분은 데이터 엔지니어링이다.
- 데이터 수집→처리→저장→분석까지 맡기 때문에 사실상 엔지니어의 역할이 대부분이다.
- 처리와 저장 부분에서 L→W→M로 가는 구성을 만들기 때문에 엔지니어링에 대한 시간이 훨씬 많이 걸린다. 
- 캐글이나 데이콘에서 제공되는 데이터들은 모두 정제가 되어있기 때문에 분석만 하면 됐지만, 앞으로 사용할 모든 데이터가 정제되어 있지는 않다. 이런 데이터를 전처리하고 분석에 활용할 수 있는 데이터로 처리하는 과정까지 생각보다 오래 걸릴 수 있고, 그에 따른 엔지니어링의 분야가 아주 광범위하다.
  - GIGO(Garbage In Garbage Out): 쓰레기같은 데이터가 들어가면 쓰레기같은 분석이 나온다.. 좋은 데이터를 잘 수집하고 관리, 처리하는 게 훨씬 좋다.

# 과거의 데이터 아키텍처
- 과거 데이터 관리 아키텍처의 한계로는,
  1. 구축 시스템의 가격이 비쌌다.
  2. 데이터의 용도가 정해져 있었다.
     - 비즈니스에 맞게 스키마를 미리 만들어 놓아야 했다. (RDBMS의 특징) 대표적으로 CREATE TABLE이라는 쿼리가 있다. 컬럼의 이름, 속성 등을 지정해서 컬럼을 만들어둔다. 반드시 데이터는 테이블에 맞게 들어가야 했다. 데이터의 변동이 별로 없고 효율적이고 정확한 DB 모델링이 굉장히 중요할 때 사용했다. 이렇게 처리하는 방법을 ETL이라고 한다.
  3. 데이터의 수집처가 일정했다.
## ETL
- Extract 추출 Transform 변형 Load 적재 (적재!=저장)
- 데이터의 형식이 거의 지정되어 있고, 변동이 없는 환경에서의 데이터 파이프라인을 ETL이라고 한다.
- 가공되지 않은 데이터를 가공해서 사용한다.
- RDBMS를 사용하던 시기에는 ETL을 할 수 밖에 없었다. 데이터가 하나씩 들어오니 ETL을 수행할 수 있었다.
- Extract 추출? 
  - 데이터를 발생시킨다. (sql, 크롤링, 로그 등등)
- Transform 변형? 
  - 추출한 데이터의 자료형 변환, 필요한 부분을 자르는 등의 작업을 미리 정해놓은 스키마(논리 구조)에 맞게 변환
- Load 적재? 
  - 변환된 데이터를 저장(적재), 원하는 스키마에 데이터를 INSERT

# 현재의 데이터 아키텍처
- 다양하고 형태를 예측하기가 불가능한 데이터
  - 다양한 채널로 데이터를 받다보니, 데이터가 누락되거나 잘못된 데이터가 생기기도 하는 등 예측 불가능한, 정형화되어있지 않은 데이터가 들어왔다
- 데이터의 형식이 다양해졌다.
  - 실시간성을 요구하는 기능들
  - 빨라지는 기능 추가 (데이터가 Transformation에 몰리게 되며 병목현상 발생)
  - 실시간 로그
  - 비정형 데이터 (정형데이터보다 비정형데이터가 훨씬 많은 가치를 갖게 됨)
  - 서드파티 데이터 (다른 회사 데이터도 사용 가능해짐)
    ⇒ 스키마를 정의하는게 매우 힘들어졌다.
- 저렴한 컴퓨터를 사용하게 됐다.
  - 일반적인 회사에서는 컴퓨터 파워에 대한 비용 최적화보다 비즈니스와 속도를 최적화하는 쪽의 이득이 크다.
  - 쏟아지는 데이터들을 Scale-Up으로 컴퓨터 덩치를 키우면서 감당하기에는 비용과 시간이 많이 든다.
  - Scale-Out 방식으로 최대한 많은 양의 데이터를 미리 저장해두는 게 훨씬 경제적이었다.
## ELT
- Extract 추출 Load 일단 저장 Transform 쓰임새에 따라 변환
- 현재 데이터의 운용 방식이다.
- 데이터를 추출해서 일단 저장한다. (html 문서 자체를 일단 저장) ⇒ 레이크 구축
- 저장한 데이터를 쓰임새에 따라 변환 ⇒ 웨어하우스 구축
- 일단 저장하고 필요할 때 변형하자는 식으로 비즈니스 패러다임이 바뀌었다.
- 스파크를 이용하는 경우에는?
  1. 스파크를 이용해서 데이터 및 로그에서 데이터를 추출
     - 크롤링만 추출이 아니다. 쌓여진 데이터에서 가지고 오면 그게 추출
  2. 스파크나 플링크 등을 이용해 어느정도 정리 후 저장
     - 1번과 2번을 같이 하는 경우도 종종 있다. 최소한의 처리만 하고 다시 저장을 하는 것
  3. 어플리케이션 또는 분석 툴에서 이용 가능하도록 변환

# 최신의 데이터 인프라 트렌드
- 클라우드가 대중화되어 있기 때문에 많은 클라우드 웨어하우스 존재
- 하둡에서 databricks, presto로 넘어가기는 하나, 전부 하둡 기반이며, 다시 하둡으로 넘어오기도 한다.
- 실시간 빅데이터 처리
- ETL → ELT
- DataFlow 자동화 (AirFlow)
- 데이터 분석팀을 따로 두기보다 누구나 분석할 수 있도록
- 중앙화되는 데이터 플랫폼 관리

# 데이터 아키텍처 분야
- **소스**: 데이터를 어디서 수집하는지
- **수집 및 변환**: 추출 저장 관리 (ELT)
- **저장**: 데이터를 쿼리와 처리 시스템이 쓸 수 있는 형태로 저장. 저장 과정에서 고려해야할게 굉장히 많다. (RDBMS 정형 데이터가 유리할수도, 비정형 데이터가 유리할 수도 있다.)
- **과거~예측**: 과거의 데이터를 처리하고 분석==배치 프로세싱 즉 데이터 분석을 위한 인사이트를 만든다.
- **출력**: 유저한테 제공

# Batch & Stream Processing
## Batch Processing
- 일괄(batch) 처리 방식
- 데이터를 한꺼번에 처리한다.
- **많은 양의 데이터**를 **정해진 시간**에 **한꺼번에 처리**한다.
  - 한정된 대량의 데이터
  - 특정 시간
  - 일괄 처리
- 전통적으로 쓰이는 데이터 처리 방법
- 배치 프로세싱을 하는 경우
  1. 실시간성을 보장하지 않아도 될 때
  2. 데이터를 한번에 처리할 수 있을 때
  3. 무거운 처리를 할 때 (ML학습)
- 예를 들어, 월별 1일마다 수요공급 예측, 매주 발생하는 뉴스레터, 매주 새로운 데이터로 ML 알고리즘 학습, 매일 아침 웹 스크래핑이나 크롤링, 매달 월급 지급하는 것들도 다 배치 프로세싱에 해당한다.
  - 특정 시점의 데이터를 한번에 묶어서 처리한다는 특징이 잘 보이는 예시

## Stream Processing
- **실시간으로 쏟아지는 데이터**를 **계속** 처리하는 것
- 데이터가 들어올 때마다, 현 시점 & 미래의 데이터를 처리 (그 크기는 무한하다.)
불규칙적으로 데이터가 들어오는 환경
- 여러 이벤트가 한 번에 들어올 수도 있고 오랜 시간 동안 하나도 들어오지 않을 수도 있다.
- 만약 배치 프로세싱으로 실시간 데이터 처리를 하게 된다면, 어떤 특정 시점마다 반드시 돌아가야 하기 때문에 데이터가 없어도 있어도 무조건 처리를 해야한다
  - 배치당 처리 데이터 수가 달라지면서 리소스가 비효율적으로 사용된다. (비합리적일 수 있는 환경)
- 스트림 프로세싱으로 실시간 데이터 처리를 하게 된다면, 간헐적으로 데이터가 생성되어 요청이 들어올 때마다 그에 맞춰 처리할 수 있다.
- 스트림 프로세싱을 하는 경우
  1. 실시간성을 보장해야 할 때
  2. 데이터가 여러 소스로부터 들어올 때
  3. 데이터가 가끔 들어오거나 지속적으로 들어올 때 (무한대기)
  4. 비교적 가벼운 데이터 처리를 할 때
      1. 실시간으로 계속 발생되는 데이터가 무거울 수가 없긴 하다.
      2. VR 등이 들어와서 들어오는 데이터가 굉장히 많아지게 된다면 모르지만, 아직까지는 그럴 일 없을 것으로 예상
- 예를 들어, 실시간 알림, 실시간 수요 공급 측정 및 가격 책정, 사기 거래 탐지 등에 사용된다.

## 배치 VS 스트림
- 배치: 데이터를 모아서 한번에 처리
- 스트림: 무한대기하고 있다가 데이터가 들어올 때마다 처리

## 마이크로 배치
- 데이터를 조금씩 모아 프로세싱하는 방식이다.
- 배치 프로세싱을 잘게 쪼개서 스트리밍을 흉내내는 방식
- 대표적으로 스파크 스트리밍이 있다.